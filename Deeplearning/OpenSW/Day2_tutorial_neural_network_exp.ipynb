{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tutorial_neural_network_exp.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg5AmArSoXaC"
      },
      "source": [
        "! nvcc --version  //Gpu세팅을 알아본다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fZsXr6pqToV"
      },
      "source": [
        "! cat /proc/cpuinfo   //cpu의 성능 확인(리눅스 예약어 cat)\n",
        "//colab은 구글 클라우드 시스템에 접근, 내 공간 내에서 간단한 코딩이 가능\n",
        "//웹 브라우저 상에서 코딩을 확인할 수 있는 기능\n",
        "//하나의 코드 공간은 하나의 셀"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk6SLJgOrFIO"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1C3Ns8isQU1"
      },
      "source": [
        "# 인공지능 & 머신러닝 & 딥러닝을 위해 필요한 재료\n",
        "1. 데이터가 필요할 것 같다\n",
        "  - 학습데이터(training data sample) =>85% / 평가데이터 (validation data sample) = >15%\n",
        "  -고양이의 이미지를 구분하기 위해 모델에게 알려줄 수 있는 방법은?\n",
        "  -이미지 : feature extraction(고양이의 눈, 고양이의 꼬리),[강아지 or 고양이]\n",
        "  -인풋 이미지 : 고양이, 인풋 이미지의 라벨      / - 인풋 이미지 :  고양이 저희가 학습한 모델이 특정클래스(고양이/ 강아지)라도 대답을 해줄 것이다. = > loss function => 0 , 정답률 높아짐\n",
        "  -지도학습? (이미지의 내용을 알려주는것=>이건 고양이 사진이야)\n",
        "2. 와이파이(인터넷)\n",
        "Image Classification(분류)\n",
        "핸드폰 분류\n",
        "아이폰 => 이건 아이폰이야 라벨 (annotation)\n",
        "삼성 => 이건 갤럭시야 라벨(annotation)\n",
        "3. 학습 모델이 필요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9mBn3m2rQTj"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1ozkg17vfwM"
      },
      "source": [
        "torch_version = torch.__version__\n",
        "print(f'torch version:{torch_version}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I3wnmr9v4RV"
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25GTKT_DwDx0"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XfFJEs3wiB3"
      },
      "source": [
        "#download training data sample\n",
        "train_data =  datasets.FashionMNIST(\n",
        "    root = 'data',  #다운로드 받을 파일의 경로\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor()    #transform 으로 데이터 타입을 바꿔준다. \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR5fGp_AxJ9S"
      },
      "source": [
        "# training 90으로 하는 이유는 (train : 90, test : 10), validation: 10%\n",
        "validation_data = datasets.FashionMNIST(\n",
        "    root = 'data',  #다운로드 받을 파일의 경로\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()    #transform 으로 데이터 타입을 바꿔준다. \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po_bmlPDygW_"
      },
      "source": [
        "print(train_data.train_labels.size())   #테스트 데이터가 6만개 준비되있음\n",
        "print(validation_data.test_labels.size())   #테스트 데이터가 1만개 준비되있음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34QihDyXy1g7"
      },
      "source": [
        "fig = plt.figure(figsize = (12,12)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ntvmqBEzJ1-"
      },
      "source": [
        "columns, rows = 4, 4\n",
        "for idx in range(columns * rows + 1):\n",
        "    random_index = torch.randint(len(train_data), size=(1,)).item()\n",
        "    input_img, input_label = train_data[random_index]\n",
        "    print(input_img.size()) #torch.Size([1, 28, 28])의 경우 [색상, 가로, 세로] => 어떤 형태의 텐서를 입력했을 때 받을 사이즈를 확인하는 것이 중요하다(행렬의 모양 확인)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDyKsPPi1QAV"
      },
      "source": [
        "fig = plt.figure(figsize=(12, 12))\n",
        "columns, rows = 3, 3\n",
        "# image visualization\n",
        "for idx in range(1, columns * rows + 1):\n",
        "    random_idx = torch.randint(len(train_data), size=(1,)).item()\n",
        "    input_img, input_label = train_data[random_idx]\n",
        "    plt.title(f'{idx}')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(input_img.squeeze())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Kho1nm6oup"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwcQj3Mg71--"
      },
      "source": [
        "def set_manual_seed(seed = 42):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  # torch.tandom.manual_seed(seed)\n",
        "  # torch.cuda.random.manual_seed(seed)\n",
        "  # torch.cuda.random.manual_seed_all(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBTEl2dL8UN5"
      },
      "source": [
        "set_manual_seed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY9Ex3VG8jPe"
      },
      "source": [
        "random_value = random.randint(1,10) #랜덤 변수를 고정시키기 위함 seed의 에러를 줄여줌\n",
        "print(random_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll3vVBzM9D6G"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Compose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEGOX1h_9aHI"
      },
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "validation_data = datasets.FashionMNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform=ToTensor()\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8i1zYUC92N1"
      },
      "source": [
        "#dataloader 데이터를 보낼 장소 지정\n",
        "batch_size =  128      #나눠서 연산 진행 stholastic Gradient Decent 한번에 연산할 갯수 정함\n",
        "train_loader = DataLoader(train_data,batch_size=batch_size)\n",
        "validation_loader = DataLoader(validation_data,batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6KIukzv_LQc"
      },
      "source": [
        "x_inputs,x_labels = next(iter(train_loader))  #train_loader은 object기 때문에 next(iter)를 사용하면 for문을 한번만 돈다. static function "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lTAIxm0_QQz"
      },
      "source": [
        "x_inputs.size() #[개수, 색상, 가로, 세로]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrFIiQEs_cX3"
      },
      "source": [
        "input_image = x_inputs[0].flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKxHlHW7AMqB"
      },
      "source": [
        "#이건 좀 더 알아보기 어려움\n",
        "input_image.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDOFkk0nAZ8a"
      },
      "source": [
        "input_tesnr = torch.randint(2,(4,4))\n",
        "print(input_tesnr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol1_kU2IE7tg"
      },
      "source": [
        "input_tesnr.flatten()     #일렬로 serialize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7euJUDhPAuR3"
      },
      "source": [
        "input_tesnr = torch.randint(2,(2,2)).to('cuda') #gpu메모리에서 연산할 준비가 되어있다. \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz4u9qd_BJYq"
      },
      "source": [
        "#neural network\n",
        "# class NeuralNet(nn.Module): #module 클래스의 인터페이스 상속받는다.\n",
        "#     def __init__(self):\n",
        "#       super(NeuralNet,self).__init__()\n",
        "#       #image shape or size : [128,1,28,28]  Number of batch, Channel size(3,1), H:28, W:28 비밀번호 키로 생각하자\n",
        "#       self.feature_flatten = nn.Flatten()\n",
        "#       self.model_chain = nn.Sequential(   #다계층의 레이어로 구성된 뉴럴 네트워크, 모델을 쌓는 부분\n",
        "#           #748                             \n",
        "#           nn.Linear(28*28,512), #1차원 벡터로 나열 시키는 것=>일렬로 직렬화 크기를 지정해준다. 512은 28*28중에 좀 확실한 값을 정해봐\n",
        "#           nn.ReLu(),    #확실한 값만 전달\n",
        "#           nn.Linear(512,512),   #다시 값을 받는다, 가중치를 학습 128~2048로 보통 사용한다.\n",
        "#           nn.ReLu(),\n",
        "#           nn.Linear(512,10),    #구분하려는 클래스의 개수만큼\n",
        "#           #고양이일 확률은 1.543, 강아지일 확률은 0.324 이기 때문에 클래스의 개수만큼 맞춰줘야 한다. 확률이 높은 값을 취한다. \n",
        "#           nn.ReLu()\n",
        "#       )  \n",
        "\n",
        "#     def forward(self,x):\n",
        "#       \"\"\"\n",
        "#         :x pram: input image tensor(batch, channel, geifht, width)\n",
        "#       \"\"\"\n",
        "#       print(f'flatten None')\n",
        "#       x=self.reature_flatten(x)     =>오타 찾기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvDE227rH1RW"
      },
      "source": [
        "# neural network\n",
        "class NeuralNet(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        # image shape or size: [1, 28, 28] Number of batch, Channel size (3,1), H: 28, W: 28\n",
        "        self.feature_flatten = nn.Flatten()\n",
        "        self.model_chain = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        ) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "            :x pram: input image tensor (batch, channel, height, widht)\n",
        "        \"\"\"\n",
        "        x = self.feature_flatten(x)\n",
        "        logits = self.model_chain(x)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpwIe0B7E0Ma"
      },
      "source": [
        "model = NeuralNet()\n",
        "input_tensor = torch.randn((1, 28, 28))\n",
        "prediction = model(input_tensor)  #예측한 10개의 결과값 ReLuvalue\n",
        "print(prediction.size())   \n",
        "print(prediction.size()[0]) \n",
        "\n",
        "numpy_prediction = prediction.detach().cpu().numpy()  #detach 를 통해 cpu연산으로 바꾸고 numpy로 배열로 바꾼다. 최종적으로 얻어야 할 값, 형변환을 해준다. \n",
        "print(numpy_prediction.flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BakJ8Y2Kpvj"
      },
      "source": [
        "#위에서 선언한 device cuda연산을 하기 위해 사용한다. model과 data에 to cuda\n",
        "model = NeuralNet().to(device)\n",
        "#0에 수렴하면 할수록 우리 모델이 좋다라는 증거\n",
        "loss_fn = nn.CrossEntropyLoss()  \n",
        "#0에 수렴할 수 있도록 오토 미분을 자동화하는 함수\n",
        "optim = torch.optim.SGD(model.parameters(), lr = 1e-3)   #sthocastic Gradient Decent\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU7LBFRbLm35"
      },
      "source": [
        "def train_op(train_loader, model, loss_fn, optim):\n",
        "    # number of train dataset: 60K\n",
        "    total_size = len(train_loader.dataset)\n",
        "    for batch, (input_x, input_y) in enumerate(train_loader):\n",
        "        input_x, input_y = input_x.to(device), input_y.to(device) #to(device) cuda연산을 통해 매우 빠른 연산이 되는것을 확인할 수 있다. \n",
        "        \n",
        "        # compute error distance\n",
        "        prediction = model(input_x)\n",
        "        loss = loss_fn(prediction, input_y)\n",
        "\n",
        "        # backProb\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            print(f'loss function valu: {loss.item()}, current batch:{batch * total_size}/{total_size}')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}